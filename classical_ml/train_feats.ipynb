{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8736734",
   "metadata": {},
   "source": [
    "This notebook provides a template for training classical ML models using k-fold cross validation. The first part, Configurations, is the only section that needs to be editted. Editting the automated code is only needed if a custom pipeline is needed.\n",
    "\n",
    "#### Classical ML Workflow\n",
    "\n",
    "1. Convert dataset into .h5 file. See `wearablebp_benchmarks/datasets_to_h5.ipynb`\n",
    "2. Create folder in `wearablebp_benchmarks/classical_ml` with feature extractor name. Build and run feature extraction algorithm.\n",
    "3. Save features in `wearablebp_benchmarks/results/features/`. Use naming conventions specified below.\n",
    "4. Use `wearablebp_benchmarks/classical_ml/train_feats.ipynb` to train model using features extracted in 3. Model is saved in .pkl file using the same name in 3.\n",
    "5. Use `wearablebp_benchmarks/make_plots.ipynb` to visualize data and compute Explained Deviation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8d861dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import dill as pickle\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be5c2fbd",
   "metadata": {},
   "source": [
    "# Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ca916cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        \n",
    "        # set model name based on results naming convention (see wearablebp/README.md)\n",
    "        self.dataset_name = 'mimic'\n",
    "        self.filter_name = 'hasandazeh19'\n",
    "        self.alg_name = 'hasandazeh19'\n",
    "        self.datapath = '../results/features/features_' + self.dataset_name + '_' + self.filter_name + '_' + self.alg_name + '.csv'\n",
    "        \n",
    "        # assign feature columns and SBP/DBP columns\n",
    "        if ('provided' in self.dataset_name) or ('features' in self.dataset_name):\n",
    "            self.sbp_col = '4'\n",
    "            self.dbp_col = '5'\n",
    "            self.feature_cols = np.arange(11, 101).astype(str)\n",
    "        else:\n",
    "            self.sbp_col = 'SBP'\n",
    "            self.dbp_col = 'DBP'\n",
    "\n",
    "            df = pd.read_csv(self.datapath)\n",
    "            self.feature_cols = df.columns[(df.columns != 'SBP') & (df.columns != 'DBP') & \n",
    "                                           (df.columns != 'MBP') & (df.columns != 'segment_num') \n",
    "                                           & (df.columns != 'subject_id')]\n",
    "        \n",
    "        # configure machine learning estimators and other hyperparameters\n",
    "        self.k_folds = 10\n",
    "        self.scaler = preprocessing.StandardScaler()\n",
    "        self.sbp_models = [RandomForestRegressor(n_jobs=4,n_estimators=100), \n",
    "                           AdaBoostRegressor(n_estimators=200),\n",
    "                           LinearRegression(n_jobs=4),\n",
    "                           DecisionTreeRegressor()\n",
    "                          ]\n",
    "        self.sbp_model_names = ['RandomForest', 'AdaBoost', 'Linear', 'DecisionTree']\n",
    "        self.dbp_models = [RandomForestRegressor(n_jobs=4,n_estimators=100), \n",
    "                           AdaBoostRegressor(n_estimators=200),\n",
    "                           LinearRegression(n_jobs=4),\n",
    "                           DecisionTreeRegressor()\n",
    "                          ]\n",
    "        self.dbp_model_names = ['RandomForest', 'AdaBoost', 'Linear', 'DecisionTree']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139a293e",
   "metadata": {},
   "source": [
    "# Automated Code (no configuration needed unless using custom pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5db830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models: RandomForest for SBP and RandomForest for DBP\n",
      "Training fold number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:01<00:13,  1.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:03<00:11,  1.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:04<00:09,  1.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:06<00:07,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:07<00:06,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:09<00:04,  1.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:10<00:03,  1.54s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:12<00:01,  1.52s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:13<00:00,  1.53s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:13<00:41, 13.80s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models: AdaBoost for SBP and AdaBoost for DBP\n",
      "Training fold number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 11%|█         | 1/9 [00:03<00:29,  3.68s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:07<00:25,  3.67s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 33%|███▎      | 3/9 [00:10<00:21,  3.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:14<00:18,  3.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 5/9 [00:18<00:14,  3.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 67%|██████▋   | 6/9 [00:21<00:10,  3.65s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:25<00:07,  3.64s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 89%|████████▉ | 8/9 [00:29<00:03,  3.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 9/9 [00:32<00:00,  3.64s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:46<00:38, 19.49s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:00<00:00, 72.46it/s]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:46<00:13, 13.68s/it]\n",
      "  0%|          | 0/9 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Models: Linear for SBP and Linear for DBP\n",
      "Training fold number 1\n",
      "Training fold number 2\n",
      "Training fold number 3\n",
      "Training fold number 4\n",
      "Training fold number 5\n",
      "Training fold number 6\n",
      "Training fold number 7\n",
      "Training fold number 8\n",
      "Training fold number 9\n",
      "Training Models: DecisionTree for SBP and DecisionTree for DBP\n",
      "Training fold number 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 2/9 [00:00<00:00, 10.39it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 2\n",
      "Training fold number 3\n",
      "Training fold number 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 4/9 [00:00<00:00, 10.47it/s]\u001b[A\n",
      " 67%|██████▋   | 6/9 [00:00<00:00, 10.42it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 5\n",
      "Training fold number 6\n",
      "Training fold number 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 7/9 [00:00<00:00, 10.25it/s]\u001b[A\n",
      "100%|██████████| 9/9 [00:00<00:00, 10.41it/s]\u001b[A\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold number 8\n",
      "Training fold number 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "opt = options()\n",
    "df = pd.read_csv(opt.datapath)\n",
    "\n",
    "# make changes from provided features.csv on github\n",
    "# available at https://github.com/navidhasanzadeh/BPPPG\n",
    "# features extracted from script have been filtered, so this part is unneeded\n",
    "if ('provided' in opt.datapath) or ('features' in opt.dataset_name):\n",
    "    df = df.drop(['0','1','2','3','6','7','8','9'], axis=1)\n",
    "    df = df.replace([np.inf, -np.inf],np.nan)\n",
    "    df = df.fillna(df.mean())\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.drop(df[df['4'] < 90].index)\n",
    "    df = df.drop(df[df['5'] < 40].index)\n",
    "    df = df.drop(df[df['10'] < 50].index)\n",
    "    df = df.drop(df[df['4'] > 200].index)\n",
    "    df = df.drop(df[df['5'] > 100].index)\n",
    "    df = df.drop(df[df['10'] > 140].index)\n",
    "    df = df.drop(['10'], axis=1)\n",
    "else:\n",
    "    df = df.drop(df[df[opt.sbp_col] < 90].index)\n",
    "    df = df.drop(df[df[opt.dbp_col] < 40].index)\n",
    "    df = df.drop(df[df[opt.sbp_col] > 200].index)\n",
    "    df = df.drop(df[df[opt.dbp_col] > 100].index)\n",
    "feature_df = df.copy()\n",
    "\n",
    "# build classical ML model\n",
    "fold_size = int(len(feature_df)/opt.k_folds)\n",
    "sbp_std = feature_df[opt.sbp_col].std()\n",
    "dbp_std = feature_df[opt.dbp_col].std()\n",
    "sbp_model_results = {}\n",
    "dbp_model_results = {}\n",
    "for m in tqdm(range(len(opt.sbp_models))):\n",
    "    sbp_ests = np.array([])\n",
    "    sbp_gts = np.array([])\n",
    "    sbp_maes = np.array([])\n",
    "    sbp_mes = np.array([])\n",
    "    sbp_raw_model_result = {}\n",
    "    dbp_ests = np.array([])\n",
    "    dbp_gts = np.array([])\n",
    "    dbp_maes = np.array([])\n",
    "    dbp_mes = np.array([])\n",
    "    dbp_raw_model_result = {}\n",
    "    print('Training Models: ' + opt.sbp_model_names[m] + ' for SBP and ' + opt.sbp_model_names[m] + ' for DBP')\n",
    "    for i in tqdm(range(1, opt.k_folds)):\n",
    "        print('Training ' + 'fold number ' + str(i))\n",
    "        trainData = feature_df.loc[0:i*fold_size]\n",
    "        trainData = trainData.append(feature_df.loc[(i+1)*fold_size:])\n",
    "        testData = feature_df.loc[i*fold_size:(i+1)*fold_size]\n",
    "        Xy_cols = np.append([opt.sbp_col, opt.dbp_col], opt.feature_cols)\n",
    "        trainData = trainData[Xy_cols]\n",
    "        testData = testData[Xy_cols]\n",
    "\n",
    "        X_train = np.array(trainData[opt.feature_cols])\n",
    "        y_train = np.array(trainData[[opt.sbp_col, opt.dbp_col]])\n",
    "        X_test = np.array(testData[opt.feature_cols])\n",
    "        y_test = np.array(testData[[opt.sbp_col, opt.dbp_col]])    \n",
    "\n",
    "        scaler = opt.scaler.fit(X_train)\n",
    "        X_train = scaler.transform(X_train) \n",
    "        X_test = scaler.transform(X_test)   \n",
    "        \n",
    "        X_train[np.isinf(X_train)] = 0\n",
    "        X_train[np.isnan(X_train)] = 0\n",
    "        X_test[np.isinf(X_test)] = 0\n",
    "        X_test[np.isnan(X_test)] = 0\n",
    "\n",
    "        sbp_model = opt.sbp_models[m]\n",
    "        sbp_model.fit(X_train, y_train[:, 0])\n",
    "        sbp_est = sbp_model.predict(X_test) \n",
    "        dbp_model = opt.dbp_models[m]\n",
    "        dbp_model.fit(X_train, y_train[:, 1])\n",
    "        dbp_est = dbp_model.predict(X_test)\n",
    "        \n",
    "        sbp_gts = np.append(sbp_gts, y_test[:, 0])\n",
    "        sbp_ests = np.append(sbp_ests, sbp_est)\n",
    "        sbp_mes = np.append(sbp_mes, sbp_est - y_test[:, 0])\n",
    "        dbp_gts = np.append(dbp_gts, y_test[:, 1])\n",
    "        dbp_ests = np.append(dbp_ests, dbp_est)\n",
    "        dbp_mes = np.append(dbp_mes, dbp_est - y_test[:, 1])\n",
    "    \n",
    "    sbp_model_result = {}\n",
    "    sbp_model_result['raw ests'] = sbp_ests\n",
    "    sbp_model_result['raw gts'] = sbp_gts\n",
    "    sbp_model_result['bias'] = (sbp_ests - sbp_gts).mean()\n",
    "    sbp_model_result['err std'] = (sbp_ests - sbp_gts).std()\n",
    "    sbp_model_result['ED'] = sbp_std/(sbp_ests - sbp_gts).std()\n",
    "    sbp_model_result['dist std'] = sbp_std\n",
    "    sbp_model_results[opt.sbp_model_names[m]] = sbp_model_result\n",
    "    dbp_model_result = {}\n",
    "    dbp_model_result['raw ests'] = dbp_ests\n",
    "    dbp_model_result['raw gts'] = dbp_gts\n",
    "    dbp_model_result['bias'] = (dbp_ests - dbp_gts).mean()\n",
    "    dbp_model_result['err std'] = (dbp_ests - dbp_gts).std()\n",
    "    dbp_model_result['ED'] = dbp_std/(dbp_ests - dbp_gts).std()\n",
    "    sbp_model_result['dist std'] = sbp_std\n",
    "    dbp_model_results[opt.dbp_model_names[m]] = dbp_model_result\n",
    "\n",
    "pickle_dict = {'sbp': sbp_model_results, 'dbp': dbp_model_results, 'opt': opt}\n",
    "with open('../results/training/' + opt.dataset_name + '_' + opt.filter_name + '_' + opt.alg_name + '.pickle', 'wb') as f:\n",
    "    pickle.dump(pickle_dict, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
